{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "glove_file = 'glove/glove.6B.50d.txt'\n",
    "glove_dim = 50\n",
    "#glove_file = 'glove/glove.840B.300d.txt'\n",
    "#glove_dim = 300\n",
    "use_lemmatization = False\n",
    "\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "def load_glove_vocab(wv_file, wv_dim):\n",
    "    vocab = set()\n",
    "    with open(wv_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            elems = line.split()\n",
    "            token = normalize_text(''.join(elems[0:-wv_dim]))\n",
    "            vocab.add(token)\n",
    "    return vocab\n",
    "\n",
    "def build_embedding(wv_file, wv_dim, target_vocab):\n",
    "    vocab_size = len(target_vocab)\n",
    "    emb = np.random.uniform(-1, 1, (vocab_size, wv_dim))\n",
    "    emb[0] = 0 # <PAD> should be all 0 (using broadcast)\n",
    "\n",
    "    w2id = {w: i for i, w in enumerate(target_vocab)}\n",
    "    with open(wv_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            elems = line.split()\n",
    "            token = normalize_text(''.join(elems[0:-wv_dim]))\n",
    "            if token == '<PAD>':\n",
    "                print(token)\n",
    "            if token in w2id:\n",
    "                emb[w2id[token]] = [float(v) for v in elems[-wv_dim:]]\n",
    "    return emb\n",
    "\n",
    "def token2id(docs, vocab, unk_id=None):\n",
    "    w2id = {w: i for i, w in enumerate(vocab)}\n",
    "    ids = [[w2id[w] if w in w2id else unk_id for w in doc] for doc in docs]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_vocab = load_glove_vocab(glove_file, glove_dim) \n",
    "#print('glove loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am proud of your achievements']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train = []\n",
    "#docs_raw.append('Based on fully-aware attention, we propose an end-to-end architecture qaz123')\n",
    "#docs_raw.append('Teaching machines to read, process and comprehend text and then answer questions is one of key problems in artificial intelligence')\n",
    "docs_train.append('I am proud of your achievements')\n",
    "docs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love you mum</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stop saying bullshit</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>congratulations on your acceptance</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The assignment is too long</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I want to go play</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>she did not answer my text</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Your stupidity has no limit</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>how many points did he score</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>my algorithm performs poorly</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I got approved</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stop shouting at me</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sounds like a fun plan ha ha</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>no one likes him</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the game just finished</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I will celebrate soon</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>So sad you are not coming</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>She is my dearest love</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Good job</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>It was funny lol</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>candy is life</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The chicago cubs won again</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I am hungry</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I am so excited to see you after so long</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>you did well on you exam</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lets brunch some day</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>This specialization is great</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>you could not solve it</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>I am so happy for you</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Congrats on the new job</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>I am proud of you forever</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>I want to eat</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>That catcher sucks</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>The first base man got the ball</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>this is bad</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>you did not do your homework</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>I will have a cheese cake</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>do you have a ball</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>the lectures are great though</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Are you down for baseball this afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>what are the rules of the game</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>I am always working</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>where is the stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>She is the cutest person I have ever seen</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>vegetables are healthy</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>he is handsome</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>too bad that you were not here</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>you are a loser</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>I love indian food</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Who is down for a restaurant</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>he had to make a home run</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>I am ordering food</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>What is wrong with you</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I love you</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>great job</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0  1   2     3\n",
       "0                       never talk to me again  3 NaN   NaN\n",
       "1              I am proud of your achievements  2 NaN   NaN\n",
       "2               It is the worst day in my life  3 NaN   NaN\n",
       "3                             Miss you so much  0 NaN   [0]\n",
       "4                                 food is life  4 NaN   NaN\n",
       "5                               I love you mum  0 NaN   NaN\n",
       "6                         Stop saying bullshit  3 NaN   NaN\n",
       "7           congratulations on your acceptance  2 NaN   NaN\n",
       "8                  The assignment is too long   3 NaN   NaN\n",
       "9                            I want to go play  1 NaN   [3]\n",
       "10                 she did not answer my text   3 NaN   NaN\n",
       "11                 Your stupidity has no limit  3 NaN   NaN\n",
       "12                how many points did he score  1 NaN   NaN\n",
       "13                my algorithm performs poorly  3 NaN   NaN\n",
       "14                              I got approved  2 NaN   NaN\n",
       "15                         Stop shouting at me  3 NaN   NaN\n",
       "16                Sounds like a fun plan ha ha  2 NaN   NaN\n",
       "17                            no one likes him  3 NaN   NaN\n",
       "18                      the game just finished  1 NaN   [2]\n",
       "19                       I will celebrate soon  2 NaN   NaN\n",
       "20                   So sad you are not coming  3 NaN   NaN\n",
       "21                      She is my dearest love  0 NaN   [1]\n",
       "22                                    Good job  2 NaN   [4]\n",
       "23                            It was funny lol  2 NaN   NaN\n",
       "24                              candy is life   2 NaN   NaN\n",
       "25                  The chicago cubs won again  1 NaN   NaN\n",
       "26                                 I am hungry  4 NaN   NaN\n",
       "27    I am so excited to see you after so long  2 NaN   NaN\n",
       "28                    you did well on you exam  2 NaN   NaN\n",
       "29                        lets brunch some day  4 NaN   NaN\n",
       "..                                         ... ..  ..   ...\n",
       "102                                  Good joke  2 NaN   NaN\n",
       "103               This specialization is great  2 NaN   NaN\n",
       "104                     you could not solve it  3 NaN   NaN\n",
       "105                      I am so happy for you  2 NaN   NaN\n",
       "106                    Congrats on the new job  2 NaN   NaN\n",
       "107                  I am proud of you forever  2 NaN   NaN\n",
       "108                              I want to eat  4 NaN   NaN\n",
       "109                        That catcher sucks   1 NaN   NaN\n",
       "110            The first base man got the ball  1 NaN   NaN\n",
       "111                                this is bad  3 NaN   NaN\n",
       "112               you did not do your homework  3 NaN   NaN\n",
       "113                  I will have a cheese cake  4 NaN   NaN\n",
       "114                         do you have a ball  1 NaN   NaN\n",
       "115             the lectures are great though   2 NaN   NaN\n",
       "116   Are you down for baseball this afternoon  1 NaN   NaN\n",
       "117             what are the rules of the game  1 NaN   NaN\n",
       "118                        I am always working  3 NaN   NaN\n",
       "119                       where is the stadium  1 NaN   NaN\n",
       "120  She is the cutest person I have ever seen  0 NaN   [4]\n",
       "121                     vegetables are healthy  4 NaN   NaN\n",
       "122                             he is handsome  0 NaN   NaN\n",
       "123             too bad that you were not here  3 NaN   NaN\n",
       "124                            you are a loser  3 NaN   NaN\n",
       "125                         I love indian food  4 NaN   NaN\n",
       "126               Who is down for a restaurant  4 NaN   NaN\n",
       "127                  he had to make a home run  1 NaN   NaN\n",
       "128                         I am ordering food  4 NaN   NaN\n",
       "129                     What is wrong with you  3 NaN   NaN\n",
       "130                                 I love you  0 NaN   NaN\n",
       "131                                  great job  2 NaN   NaN\n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('emoji/train_emoji.csv', header=None)\n",
    "docs_train = df_train[0]\n",
    "Y_train = Variable(torch.LongTensor(df_train[1].values), requires_grad=False)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a very nice raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a nice present\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he is a good friend\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am upset\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We had such a lovely dinner tonight\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>where is the food\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stop making this joke ha ha ha\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>where is the ball\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>work is hard\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This girl is messing with me\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>are you serious</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Let us go play baseball\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This stupid grader is not working \\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>work is horrible\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Congratulation for having a baby\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stop pissing me off</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>any suggestions for dinner\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I love taking breaks\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>you brighten my day\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I boiled rice\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>she is a bully\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Why are you feeling bad\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I am upset\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>give me the ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>My grandmother is the love of my life\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>enjoy your game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>valentine day is near\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I miss you so much\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>throw the ball\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>My life is so boring\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>she said yes\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>will you be my valentine\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>he can pitch really well\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dance with me\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I am hungry</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>See you at the restaurant\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I like to laugh\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I will  run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I like your jacket \\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>i miss her\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>what is your favorite baseball game\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Good job\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I love you to the stars and back\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What you did was awesome\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ha ha ha lol\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I do not want to joke\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>go away\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>yesterday we lost again\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>family is all I have\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>you are failing this exercise\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Good joke\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>You deserve this nice prize\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>I did not have breakfast</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0  1\n",
       "0                           I want to eat\\t  4\n",
       "1                       he did not answer\\t  3\n",
       "2                he got a very nice raise\\t  2\n",
       "3               she got me a nice present\\t  2\n",
       "4                ha ha ha it was so funny\\t  2\n",
       "5                     he is a good friend\\t  2\n",
       "6                              I am upset\\t  3\n",
       "7     We had such a lovely dinner tonight\\t  2\n",
       "8                       where is the food\\t  4\n",
       "9          Stop making this joke ha ha ha\\t  2\n",
       "10                      where is the ball\\t  1\n",
       "11                           work is hard\\t  3\n",
       "12           This girl is messing with me\\t  3\n",
       "13                          are you serious  3\n",
       "14                Let us go play baseball\\t  1\n",
       "15     This stupid grader is not working \\t  3\n",
       "16                       work is horrible\\t  3\n",
       "17       Congratulation for having a baby\\t  2\n",
       "18                      stop pissing me off  3\n",
       "19             any suggestions for dinner\\t  4\n",
       "20                   I love taking breaks\\t  0\n",
       "21                    you brighten my day\\t  2\n",
       "22                          I boiled rice\\t  4\n",
       "23                         she is a bully\\t  3\n",
       "24                Why are you feeling bad\\t  3\n",
       "25                             I am upset\\t  3\n",
       "26                         give me the ball  1\n",
       "27  My grandmother is the love of my life\\t  0\n",
       "28                          enjoy your game  1\n",
       "29                  valentine day is near\\t  2\n",
       "30                     I miss you so much\\t  0\n",
       "31                         throw the ball\\t  1\n",
       "32                   My life is so boring\\t  3\n",
       "33                           she said yes\\t  2\n",
       "34               will you be my valentine\\t  2\n",
       "35               he can pitch really well\\t  1\n",
       "36                          dance with me\\t  2\n",
       "37                              I am hungry  4\n",
       "38              See you at the restaurant\\t  4\n",
       "39                        I like to laugh\\t  2\n",
       "40                              I will  run  1\n",
       "41                    I like your jacket \\t  0\n",
       "42                             i miss her\\t  0\n",
       "43    what is your favorite baseball game\\t  1\n",
       "44                               Good job\\t  2\n",
       "45       I love you to the stars and back\\t  0\n",
       "46               What you did was awesome\\t  2\n",
       "47                           ha ha ha lol\\t  2\n",
       "48                  I do not want to joke\\t  3\n",
       "49                                go away\\t  3\n",
       "50                yesterday we lost again\\t  3\n",
       "51                   family is all I have\\t  0\n",
       "52          you are failing this exercise\\t  3\n",
       "53                              Good joke\\t  2\n",
       "54            You deserve this nice prize\\t  2\n",
       "55                I did not have breakfast   4"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('emoji/tesss.csv', header=None)\n",
    "docs_test = df_test[0]\n",
    "Y_test = Variable(torch.LongTensor(df_test[1].values), requires_grad=False)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never never ADV  O\n",
      "talk talk VERB  O\n",
      "to to ADP  O\n",
      "me me PRON  O\n",
      "again again ADV  O\n"
     ]
    }
   ],
   "source": [
    "nlp_doc = nlp(docs_train[0])\n",
    "for token in nlp_doc:\n",
    "    if not token.is_punct and not token.is_space:\n",
    "        print(token.text, token.lemma_ if token.lemma_ != '-PRON-' else token.lower_ , token.pos_, token.ent_type_, token.ent_iob_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['never', 'talk', 'to', 'me', 'again'],\n",
       " ['i', 'am', 'proud', 'of', 'your', 'achievements'],\n",
       " ['it', 'is', 'the', 'worst', 'day', 'in', 'my', 'life'],\n",
       " ['miss', 'you', 'so', 'much'],\n",
       " ['food', 'is', 'life'],\n",
       " ['i', 'love', 'you', 'mum'],\n",
       " ['stop', 'saying', 'bullshit'],\n",
       " ['congratulations', 'on', 'your', 'acceptance'],\n",
       " ['the', 'assignment', 'is', 'too', 'long'],\n",
       " ['i', 'want', 'to', 'go', 'play'],\n",
       " ['she', 'did', 'not', 'answer', 'my', 'text'],\n",
       " ['your', 'stupidity', 'has', 'no', 'limit'],\n",
       " ['how', 'many', 'points', 'did', 'he', 'score'],\n",
       " ['my', 'algorithm', 'performs', 'poorly'],\n",
       " ['i', 'got', 'approved'],\n",
       " ['stop', 'shouting', 'at', 'me'],\n",
       " ['sounds', 'like', 'a', 'fun', 'plan', 'ha', 'ha'],\n",
       " ['no', 'one', 'likes', 'him'],\n",
       " ['the', 'game', 'just', 'finished'],\n",
       " ['i', 'will', 'celebrate', 'soon'],\n",
       " ['so', 'sad', 'you', 'are', 'not', 'coming'],\n",
       " ['she', 'is', 'my', 'dearest', 'love'],\n",
       " ['good', 'job'],\n",
       " ['it', 'was', 'funny', 'lol'],\n",
       " ['candy', 'is', 'life'],\n",
       " ['the', 'chicago', 'cubs', 'won', 'again'],\n",
       " ['i', 'am', 'hungry'],\n",
       " ['i', 'am', 'so', 'excited', 'to', 'see', 'you', 'after', 'so', 'long'],\n",
       " ['you', 'did', 'well', 'on', 'you', 'exam'],\n",
       " ['lets', 'brunch', 'some', 'day'],\n",
       " ['he', 'is', 'so', 'cute'],\n",
       " ['how', 'dare', 'you', 'ask', 'that'],\n",
       " ['do', 'you', 'want', 'to', 'join', 'me', 'for', 'dinner'],\n",
       " ['i', 'said', 'yes'],\n",
       " ['she', 'is', 'attractive'],\n",
       " ['you', 'suck'],\n",
       " ['she', 'smiles', 'a', 'lot'],\n",
       " ['he', 'is', 'laughing'],\n",
       " ['she', 'takes', 'forever', 'to', 'get', 'ready'],\n",
       " ['french', 'macaroon', 'is', 'so', 'tasty'],\n",
       " ['we', 'made', 'it'],\n",
       " ['i', 'am', 'excited'],\n",
       " ['i', 'adore', 'my', 'dogs'],\n",
       " ['congratulations'],\n",
       " ['this', 'girl', 'was', 'mean'],\n",
       " ['you', 'two', 'are', 'cute'],\n",
       " ['my', 'code', 'is', 'working', 'but', 'the', 'grader', 'gave', 'me', 'zero'],\n",
       " ['this', 'joke', 'is', 'killing', 'me', 'haha'],\n",
       " ['do', 'you', 'like', 'pizza'],\n",
       " ['you', 'got', 'a', 'down', 'grade'],\n",
       " ['i', 'missed', 'you'],\n",
       " ['i', 'think', 'i', 'will', 'end', 'up', 'alone'],\n",
       " ['i', 'got', 'humiliated', 'by', 'my', 'sister'],\n",
       " ['you', 'are', 'awful'],\n",
       " ['i', 'cooked', 'meat'],\n",
       " ['this', 'is', 'so', 'funny'],\n",
       " ['lets', 'exercise'],\n",
       " ['he', 'is', 'the', 'best', 'player'],\n",
       " ['i', 'am', 'going', 'to', 'the', 'stadium'],\n",
       " ['you', 'are', 'incredibly', 'intelligent', 'and', 'talented'],\n",
       " ['stop', 'shouting', 'at', 'me'],\n",
       " ['who', 'is', 'your', 'favorite', 'player'],\n",
       " ['i', 'like', 'you', 'a', 'lot'],\n",
       " ['i', 'miss', 'him'],\n",
       " ['my', 'dog', 'just', 'had', 'a', 'few', 'puppies'],\n",
       " ['i', 'hate', 'him'],\n",
       " ['i', 'want', 'chinese', 'food'],\n",
       " ['cookies', 'are', 'good'],\n",
       " ['her', 'smile', 'is', 'so', 'charming'],\n",
       " ['bravo',\n",
       "  'for',\n",
       "  'the',\n",
       "  'announcement',\n",
       "  'it',\n",
       "  'got',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'traction'],\n",
       " ['she', 'plays', 'baseball'],\n",
       " ['he', 'did', 'an', 'amazing', 'job'],\n",
       " ['the', 'baby', 'is', 'adorable'],\n",
       " ['i', 'was', 'waiting', 'for', 'her', 'for', 'two', 'hours'],\n",
       " ['funny'],\n",
       " ['i', 'like', 'it', 'when', 'people', 'smile'],\n",
       " ['i', 'love', 'dogs'],\n",
       " ['they', 'are', 'so', 'kind', 'and', 'friendly'],\n",
       " ['so', 'bad', 'that', 'you', 'can', 'not', 'come', 'with', 'us'],\n",
       " ['he', 'likes', 'baseball'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'so',\n",
       "  'impressed',\n",
       "  'by',\n",
       "  'your',\n",
       "  'dedication',\n",
       "  'to',\n",
       "  'this',\n",
       "  'project'],\n",
       " ['i', 'am', 'at', 'the', 'baseball', 'game'],\n",
       " ['bravo'],\n",
       " ['what', 'a', 'fun', 'moment'],\n",
       " ['i', 'want', 'to', 'have', 'sushi', 'for', 'dinner'],\n",
       " ['i', 'am', 'very', 'disappointed'],\n",
       " ['he', 'can', 'not', 'do', 'anything'],\n",
       " ['lol'],\n",
       " ['lets', 'have', 'food', 'together'],\n",
       " ['she', 'is', 'so', 'cute'],\n",
       " ['miss', 'you', 'my', 'dear'],\n",
       " ['i', 'am', 'looking', 'for', 'a', 'date'],\n",
       " ['i', 'am', 'frustrated'],\n",
       " ['i', 'lost', 'my', 'wallet'],\n",
       " ['you', 'failed', 'the', 'midterm'],\n",
       " ['ha', 'ha', 'ha', 'it', 'was', 'so', 'funny'],\n",
       " ['do', 'you', 'want', 'to', 'give', 'me', 'a', 'hug'],\n",
       " ['who', 'is', 'playing', 'in', 'the', 'final'],\n",
       " ['she', 'is', 'happy'],\n",
       " ['you', 'are', 'not', 'qualified', 'for', 'this', 'position'],\n",
       " ['i', 'love', 'my', 'dad'],\n",
       " ['this', 'guy', 'was', 'such', 'a', 'joke'],\n",
       " ['good', 'joke'],\n",
       " ['this', 'specialization', 'is', 'great'],\n",
       " ['you', 'could', 'not', 'solve', 'it'],\n",
       " ['i', 'am', 'so', 'happy', 'for', 'you'],\n",
       " ['congrats', 'on', 'the', 'new', 'job'],\n",
       " ['i', 'am', 'proud', 'of', 'you', 'forever'],\n",
       " ['i', 'want', 'to', 'eat'],\n",
       " ['that', 'catcher', 'sucks'],\n",
       " ['the', 'first', 'base', 'man', 'got', 'the', 'ball'],\n",
       " ['this', 'is', 'bad'],\n",
       " ['you', 'did', 'not', 'do', 'your', 'homework'],\n",
       " ['i', 'will', 'have', 'a', 'cheese', 'cake'],\n",
       " ['do', 'you', 'have', 'a', 'ball'],\n",
       " ['the', 'lectures', 'are', 'great', 'though'],\n",
       " ['are', 'you', 'down', 'for', 'baseball', 'this', 'afternoon'],\n",
       " ['what', 'are', 'the', 'rules', 'of', 'the', 'game'],\n",
       " ['i', 'am', 'always', 'working'],\n",
       " ['where', 'is', 'the', 'stadium'],\n",
       " ['she', 'is', 'the', 'cutest', 'person', 'i', 'have', 'ever', 'seen'],\n",
       " ['vegetables', 'are', 'healthy'],\n",
       " ['he', 'is', 'handsome'],\n",
       " ['too', 'bad', 'that', 'you', 'were', 'not', 'here'],\n",
       " ['you', 'are', 'a', 'loser'],\n",
       " ['i', 'love', 'indian', 'food'],\n",
       " ['who', 'is', 'down', 'for', 'a', 'restaurant'],\n",
       " ['he', 'had', 'to', 'make', 'a', 'home', 'run'],\n",
       " ['i', 'am', 'ordering', 'food'],\n",
       " ['what', 'is', 'wrong', 'with', 'you'],\n",
       " ['i', 'love', 'you'],\n",
       " ['great', 'job']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_tokens = []\n",
    "for doc in docs_train:\n",
    "    nlp_doc = nlp(doc)\n",
    "    #keep stop words \n",
    "    #spacy doesn't have stemming, only lemmatization\n",
    "    if use_lemmatization:\n",
    "        tokens = [token.lemma_ if token.lemma_ != '-PRON-' else token.lower_ for token in nlp_doc if not token.is_punct and not token.is_space]\n",
    "    else:\n",
    "        tokens = [token.lower_ for token in nlp_doc if not token.is_punct and not token.is_space]\n",
    "    docs_train_tokens.append(tokens)\n",
    "\n",
    "docs_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'want', 'to', 'eat'],\n",
       " ['he', 'did', 'not', 'answer'],\n",
       " ['he', 'got', 'a', 'very', 'nice', 'raise'],\n",
       " ['she', 'got', 'me', 'a', 'nice', 'present'],\n",
       " ['ha', 'ha', 'ha', 'it', 'was', 'so', 'funny'],\n",
       " ['he', 'is', 'a', 'good', 'friend'],\n",
       " ['i', 'am', 'upset'],\n",
       " ['we', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'],\n",
       " ['where', 'is', 'the', 'food'],\n",
       " ['stop', 'making', 'this', 'joke', 'ha', 'ha', 'ha'],\n",
       " ['where', 'is', 'the', 'ball'],\n",
       " ['work', 'is', 'hard'],\n",
       " ['this', 'girl', 'is', 'messing', 'with', 'me'],\n",
       " ['are', 'you', 'serious'],\n",
       " ['let', 'us', 'go', 'play', 'baseball'],\n",
       " ['this', 'stupid', 'grader', 'is', 'not', 'working'],\n",
       " ['work', 'is', 'horrible'],\n",
       " ['congratulation', 'for', 'having', 'a', 'baby'],\n",
       " ['stop', 'pissing', 'me', 'off'],\n",
       " ['any', 'suggestions', 'for', 'dinner'],\n",
       " ['i', 'love', 'taking', 'breaks'],\n",
       " ['you', 'brighten', 'my', 'day'],\n",
       " ['i', 'boiled', 'rice'],\n",
       " ['she', 'is', 'a', 'bully'],\n",
       " ['why', 'are', 'you', 'feeling', 'bad'],\n",
       " ['i', 'am', 'upset'],\n",
       " ['give', 'me', 'the', 'ball'],\n",
       " ['my', 'grandmother', 'is', 'the', 'love', 'of', 'my', 'life'],\n",
       " ['enjoy', 'your', 'game'],\n",
       " ['valentine', 'day', 'is', 'near'],\n",
       " ['i', 'miss', 'you', 'so', 'much'],\n",
       " ['throw', 'the', 'ball'],\n",
       " ['my', 'life', 'is', 'so', 'boring'],\n",
       " ['she', 'said', 'yes'],\n",
       " ['will', 'you', 'be', 'my', 'valentine'],\n",
       " ['he', 'can', 'pitch', 'really', 'well'],\n",
       " ['dance', 'with', 'me'],\n",
       " ['i', 'am', 'hungry'],\n",
       " ['see', 'you', 'at', 'the', 'restaurant'],\n",
       " ['i', 'like', 'to', 'laugh'],\n",
       " ['i', 'will', 'run'],\n",
       " ['i', 'like', 'your', 'jacket'],\n",
       " ['i', 'miss', 'her'],\n",
       " ['what', 'is', 'your', 'favorite', 'baseball', 'game'],\n",
       " ['good', 'job'],\n",
       " ['i', 'love', 'you', 'to', 'the', 'stars', 'and', 'back'],\n",
       " ['what', 'you', 'did', 'was', 'awesome'],\n",
       " ['ha', 'ha', 'ha', 'lol'],\n",
       " ['i', 'do', 'not', 'want', 'to', 'joke'],\n",
       " ['go', 'away'],\n",
       " ['yesterday', 'we', 'lost', 'again'],\n",
       " ['family', 'is', 'all', 'i', 'have'],\n",
       " ['you', 'are', 'failing', 'this', 'exercise'],\n",
       " ['good', 'joke'],\n",
       " ['you', 'deserve', 'this', 'nice', 'prize'],\n",
       " ['i', 'did', 'not', 'have', 'breakfast']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test_tokens = []\n",
    "for doc in docs_test:\n",
    "    nlp_doc = nlp(doc)\n",
    "    if use_lemmatization:\n",
    "        tokens = [token.lemma_ if token.lemma_ != '-PRON-' else token.lower_ for token in nlp_doc if not token.is_punct and not token.is_space]\n",
    "    else:\n",
    "        tokens = [token.lower_ for token in nlp_doc if not token.is_punct and not token.is_space]\n",
    "    docs_test_tokens.append(tokens)\n",
    "\n",
    "docs_test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['never', 'talk', 'to', 'me', 'again'],\n",
       " ['i', 'am', 'proud', 'of', 'your', 'achievements'],\n",
       " ['it', 'is', 'the', 'worst', 'day', 'in', 'my', 'life'],\n",
       " ['miss', 'you', 'so', 'much'],\n",
       " ['food', 'is', 'life'],\n",
       " ['i', 'love', 'you', 'mum'],\n",
       " ['stop', 'saying', 'bullshit'],\n",
       " ['congratulations', 'on', 'your', 'acceptance'],\n",
       " ['the', 'assignment', 'is', 'too', 'long'],\n",
       " ['i', 'want', 'to', 'go', 'play'],\n",
       " ['she', 'did', 'not', 'answer', 'my', 'text'],\n",
       " ['your', 'stupidity', 'has', 'no', 'limit'],\n",
       " ['how', 'many', 'points', 'did', 'he', 'score'],\n",
       " ['my', 'algorithm', 'performs', 'poorly'],\n",
       " ['i', 'got', 'approved'],\n",
       " ['stop', 'shouting', 'at', 'me'],\n",
       " ['sounds', 'like', 'a', 'fun', 'plan', 'ha', 'ha'],\n",
       " ['no', 'one', 'likes', 'him'],\n",
       " ['the', 'game', 'just', 'finished'],\n",
       " ['i', 'will', 'celebrate', 'soon'],\n",
       " ['so', 'sad', 'you', 'are', 'not', 'coming'],\n",
       " ['she', 'is', 'my', 'dearest', 'love'],\n",
       " ['good', 'job'],\n",
       " ['it', 'was', 'funny', 'lol'],\n",
       " ['candy', 'is', 'life'],\n",
       " ['the', 'chicago', 'cubs', 'won', 'again'],\n",
       " ['i', 'am', 'hungry'],\n",
       " ['i', 'am', 'so', 'excited', 'to', 'see', 'you', 'after', 'so', 'long'],\n",
       " ['you', 'did', 'well', 'on', 'you', 'exam'],\n",
       " ['lets', 'brunch', 'some', 'day'],\n",
       " ['he', 'is', 'so', 'cute'],\n",
       " ['how', 'dare', 'you', 'ask', 'that'],\n",
       " ['do', 'you', 'want', 'to', 'join', 'me', 'for', 'dinner'],\n",
       " ['i', 'said', 'yes'],\n",
       " ['she', 'is', 'attractive'],\n",
       " ['you', 'suck'],\n",
       " ['she', 'smiles', 'a', 'lot'],\n",
       " ['he', 'is', 'laughing'],\n",
       " ['she', 'takes', 'forever', 'to', 'get', 'ready'],\n",
       " ['french', 'macaroon', 'is', 'so', 'tasty'],\n",
       " ['we', 'made', 'it'],\n",
       " ['i', 'am', 'excited'],\n",
       " ['i', 'adore', 'my', 'dogs'],\n",
       " ['congratulations'],\n",
       " ['this', 'girl', 'was', 'mean'],\n",
       " ['you', 'two', 'are', 'cute'],\n",
       " ['my', 'code', 'is', 'working', 'but', 'the', 'grader', 'gave', 'me', 'zero'],\n",
       " ['this', 'joke', 'is', 'killing', 'me', 'haha'],\n",
       " ['do', 'you', 'like', 'pizza'],\n",
       " ['you', 'got', 'a', 'down', 'grade'],\n",
       " ['i', 'missed', 'you'],\n",
       " ['i', 'think', 'i', 'will', 'end', 'up', 'alone'],\n",
       " ['i', 'got', 'humiliated', 'by', 'my', 'sister'],\n",
       " ['you', 'are', 'awful'],\n",
       " ['i', 'cooked', 'meat'],\n",
       " ['this', 'is', 'so', 'funny'],\n",
       " ['lets', 'exercise'],\n",
       " ['he', 'is', 'the', 'best', 'player'],\n",
       " ['i', 'am', 'going', 'to', 'the', 'stadium'],\n",
       " ['you', 'are', 'incredibly', 'intelligent', 'and', 'talented'],\n",
       " ['stop', 'shouting', 'at', 'me'],\n",
       " ['who', 'is', 'your', 'favorite', 'player'],\n",
       " ['i', 'like', 'you', 'a', 'lot'],\n",
       " ['i', 'miss', 'him'],\n",
       " ['my', 'dog', 'just', 'had', 'a', 'few', 'puppies'],\n",
       " ['i', 'hate', 'him'],\n",
       " ['i', 'want', 'chinese', 'food'],\n",
       " ['cookies', 'are', 'good'],\n",
       " ['her', 'smile', 'is', 'so', 'charming'],\n",
       " ['bravo',\n",
       "  'for',\n",
       "  'the',\n",
       "  'announcement',\n",
       "  'it',\n",
       "  'got',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'traction'],\n",
       " ['she', 'plays', 'baseball'],\n",
       " ['he', 'did', 'an', 'amazing', 'job'],\n",
       " ['the', 'baby', 'is', 'adorable'],\n",
       " ['i', 'was', 'waiting', 'for', 'her', 'for', 'two', 'hours'],\n",
       " ['funny'],\n",
       " ['i', 'like', 'it', 'when', 'people', 'smile'],\n",
       " ['i', 'love', 'dogs'],\n",
       " ['they', 'are', 'so', 'kind', 'and', 'friendly'],\n",
       " ['so', 'bad', 'that', 'you', 'can', 'not', 'come', 'with', 'us'],\n",
       " ['he', 'likes', 'baseball'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'so',\n",
       "  'impressed',\n",
       "  'by',\n",
       "  'your',\n",
       "  'dedication',\n",
       "  'to',\n",
       "  'this',\n",
       "  'project'],\n",
       " ['i', 'am', 'at', 'the', 'baseball', 'game'],\n",
       " ['bravo'],\n",
       " ['what', 'a', 'fun', 'moment'],\n",
       " ['i', 'want', 'to', 'have', 'sushi', 'for', 'dinner'],\n",
       " ['i', 'am', 'very', 'disappointed'],\n",
       " ['he', 'can', 'not', 'do', 'anything'],\n",
       " ['lol'],\n",
       " ['lets', 'have', 'food', 'together'],\n",
       " ['she', 'is', 'so', 'cute'],\n",
       " ['miss', 'you', 'my', 'dear'],\n",
       " ['i', 'am', 'looking', 'for', 'a', 'date'],\n",
       " ['i', 'am', 'frustrated'],\n",
       " ['i', 'lost', 'my', 'wallet'],\n",
       " ['you', 'failed', 'the', 'midterm'],\n",
       " ['ha', 'ha', 'ha', 'it', 'was', 'so', 'funny'],\n",
       " ['do', 'you', 'want', 'to', 'give', 'me', 'a', 'hug'],\n",
       " ['who', 'is', 'playing', 'in', 'the', 'final'],\n",
       " ['she', 'is', 'happy'],\n",
       " ['you', 'are', 'not', 'qualified', 'for', 'this', 'position'],\n",
       " ['i', 'love', 'my', 'dad'],\n",
       " ['this', 'guy', 'was', 'such', 'a', 'joke'],\n",
       " ['good', 'joke'],\n",
       " ['this', 'specialization', 'is', 'great'],\n",
       " ['you', 'could', 'not', 'solve', 'it'],\n",
       " ['i', 'am', 'so', 'happy', 'for', 'you'],\n",
       " ['congrats', 'on', 'the', 'new', 'job'],\n",
       " ['i', 'am', 'proud', 'of', 'you', 'forever'],\n",
       " ['i', 'want', 'to', 'eat'],\n",
       " ['that', 'catcher', 'sucks'],\n",
       " ['the', 'first', 'base', 'man', 'got', 'the', 'ball'],\n",
       " ['this', 'is', 'bad'],\n",
       " ['you', 'did', 'not', 'do', 'your', 'homework'],\n",
       " ['i', 'will', 'have', 'a', 'cheese', 'cake'],\n",
       " ['do', 'you', 'have', 'a', 'ball'],\n",
       " ['the', 'lectures', 'are', 'great', 'though'],\n",
       " ['are', 'you', 'down', 'for', 'baseball', 'this', 'afternoon'],\n",
       " ['what', 'are', 'the', 'rules', 'of', 'the', 'game'],\n",
       " ['i', 'am', 'always', 'working'],\n",
       " ['where', 'is', 'the', 'stadium'],\n",
       " ['she', 'is', 'the', 'cutest', 'person', 'i', 'have', 'ever', 'seen'],\n",
       " ['vegetables', 'are', 'healthy'],\n",
       " ['he', 'is', 'handsome'],\n",
       " ['too', 'bad', 'that', 'you', 'were', 'not', 'here'],\n",
       " ['you', 'are', 'a', 'loser'],\n",
       " ['i', 'love', 'indian', 'food'],\n",
       " ['who', 'is', 'down', 'for', 'a', 'restaurant'],\n",
       " ['he', 'had', 'to', 'make', 'a', 'home', 'run'],\n",
       " ['i', 'am', 'ordering', 'food'],\n",
       " ['what', 'is', 'wrong', 'with', 'you'],\n",
       " ['i', 'love', 'you'],\n",
       " ['great', 'job'],\n",
       " ['i', 'want', 'to', 'eat'],\n",
       " ['he', 'did', 'not', 'answer'],\n",
       " ['he', 'got', 'a', 'very', 'nice', 'raise'],\n",
       " ['she', 'got', 'me', 'a', 'nice', 'present'],\n",
       " ['ha', 'ha', 'ha', 'it', 'was', 'so', 'funny'],\n",
       " ['he', 'is', 'a', 'good', 'friend'],\n",
       " ['i', 'am', 'upset'],\n",
       " ['we', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'],\n",
       " ['where', 'is', 'the', 'food'],\n",
       " ['stop', 'making', 'this', 'joke', 'ha', 'ha', 'ha'],\n",
       " ['where', 'is', 'the', 'ball'],\n",
       " ['work', 'is', 'hard'],\n",
       " ['this', 'girl', 'is', 'messing', 'with', 'me'],\n",
       " ['are', 'you', 'serious'],\n",
       " ['let', 'us', 'go', 'play', 'baseball'],\n",
       " ['this', 'stupid', 'grader', 'is', 'not', 'working'],\n",
       " ['work', 'is', 'horrible'],\n",
       " ['congratulation', 'for', 'having', 'a', 'baby'],\n",
       " ['stop', 'pissing', 'me', 'off'],\n",
       " ['any', 'suggestions', 'for', 'dinner'],\n",
       " ['i', 'love', 'taking', 'breaks'],\n",
       " ['you', 'brighten', 'my', 'day'],\n",
       " ['i', 'boiled', 'rice'],\n",
       " ['she', 'is', 'a', 'bully'],\n",
       " ['why', 'are', 'you', 'feeling', 'bad'],\n",
       " ['i', 'am', 'upset'],\n",
       " ['give', 'me', 'the', 'ball'],\n",
       " ['my', 'grandmother', 'is', 'the', 'love', 'of', 'my', 'life'],\n",
       " ['enjoy', 'your', 'game'],\n",
       " ['valentine', 'day', 'is', 'near'],\n",
       " ['i', 'miss', 'you', 'so', 'much'],\n",
       " ['throw', 'the', 'ball'],\n",
       " ['my', 'life', 'is', 'so', 'boring'],\n",
       " ['she', 'said', 'yes'],\n",
       " ['will', 'you', 'be', 'my', 'valentine'],\n",
       " ['he', 'can', 'pitch', 'really', 'well'],\n",
       " ['dance', 'with', 'me'],\n",
       " ['i', 'am', 'hungry'],\n",
       " ['see', 'you', 'at', 'the', 'restaurant'],\n",
       " ['i', 'like', 'to', 'laugh'],\n",
       " ['i', 'will', 'run'],\n",
       " ['i', 'like', 'your', 'jacket'],\n",
       " ['i', 'miss', 'her'],\n",
       " ['what', 'is', 'your', 'favorite', 'baseball', 'game'],\n",
       " ['good', 'job'],\n",
       " ['i', 'love', 'you', 'to', 'the', 'stars', 'and', 'back'],\n",
       " ['what', 'you', 'did', 'was', 'awesome'],\n",
       " ['ha', 'ha', 'ha', 'lol'],\n",
       " ['i', 'do', 'not', 'want', 'to', 'joke'],\n",
       " ['go', 'away'],\n",
       " ['yesterday', 'we', 'lost', 'again'],\n",
       " ['family', 'is', 'all', 'i', 'have'],\n",
       " ['you', 'are', 'failing', 'this', 'exercise'],\n",
       " ['good', 'joke'],\n",
       " ['you', 'deserve', 'this', 'nice', 'prize'],\n",
       " ['i', 'did', 'not', 'have', 'breakfast']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = docs_train_tokens + docs_test_tokens\n",
    "all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<UNK>', 'brighten', 'congrats', 'was', 'the', 'grade', 'sushi', 'an', 'bullshit', 'she', 'shouting', 'chicago', 'we', 'her', 'kind', 'final', 'new', 'awesome', 'exercise', 'lovely', 'not', 'hard', 'exam', 'catcher', 'eat', 'traction', 'did', 'brunch', 'ball', 'hours', 'sounds', 'attractive', 'yesterday', 'stop', 'moment', 'enjoy', 'bully', 'raise', 'amazing', 'man', 'joke', 'dance', 'down', 'stupid', 'you', 'algorithm', 'smile', 'waiting', 'finished', 'is', 'pizza', 'code', 'horrible', 'score', 'when', 'a', 'ha', 'happy', 'lot', 'up', 'sucks', 'after', 'dear', 'date', 'rules', 'proud', 'two', 'grader', 'killing', 'humiliated', 'talented', 'have', 'cookies', 'together', 'back', 'zero', 'saying', 'adorable', 'bravo', 'one', 'dare', 'project', 'again', 'us', 'takes', 'much', 'home', 'my', 'excited', 'soon', 'with', 'poorly', 'him', 'people', 'can', 'give', 'limit', 'breakfast', 'for', 'cute', 'were', 'midterm', 'worst', 'impressed', 'tasty', 'baby', 'playing', 'but', 'of', 'like', 'qualified', 'pissing', 'feeling', 'going', 'fun', 'sister', 'pitch', 'messing', 'adore', 'points', 'said', 'announcement', 'friendly', 'miss', 'alone', 'no', 'dinner', 'solve', 'boring', 'lol', 'will', 'it', 'any', 'prize', 'celebrate', 'some', 'dogs', 'at', 'talk', 'person', 'won', 'this', 'away', 'dad', 'dog', 'game', 'girl', 'lets', 'taking', 'never', 'your', 'first', 'ordering', 'intelligent', 'life', 'haha', 'gave', 'off', 'achievements', 'are', 'too', 'here', 'all', 'in', 'they', 'throw', 'just', 'who', 'dearest', 'suggestions', 'vegetables', 'dedication', 'work', 'bad', 'congratulation', 'jacket', 'long', 'macaroon', 'laughing', 'rice', 'forever', 'to', 'answer', 'get', 'chinese', 'looking', 'job', 'run', 'plays', 'sad', 'wallet', 'wrong', 'think', 'cubs', 'always', 'valentine', 'how', 'do', 'love', 'mum', 'yes', 'made', 'meat', 'anything', 'disappointed', 'cheese', 'acceptance', 'come', 'where', 'family', 'food', 'puppies', 'ask', 'frustrated', 'candy', 'and', 'loser', 'nice', 'healthy', 'restaurant', 'really', 'failing', 'best', 'go', 'see', 'breaks', 'favorite', 'congratulations', 'making', 'afternoon', 'smiles', 'laugh', 'french', 'having', 'plan', 'likes', 'be', 'stadium', 'grandmother', 'assignment', 'on', 'day', 'well', 'me', 'suck', 'what', 'he', 'very', 'failed', 'approved', 'want', 'homework', 'why', 'text', 'play', 'working', 'missed', 'great', 'ever', 'stars', 'good', 'let', 'near', 'so', 'serious', 'am', 'make', 'many', 'boiled', 'lost', 'funny', 'coming', 'by', 'charming', 'hug', 'though', 'deserve', 'ready', 'player', 'seen', 'incredibly', 'i', 'mean', 'base', 'end', 'present', 'cooked', 'tonight', 'baseball', 'indian', 'awful', 'position', 'could', 'that', 'join', 'hate', 'lectures', 'upset', 'hungry', 'cake', 'performs', 'few', 'guy', 'such', 'had', 'cutest', 'handsome', 'friend', 'specialization', 'stupidity', 'has', 'got']\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#ignore words not in glove vocabulary\n",
    "all_docs = docs_train_tokens + docs_test_tokens\n",
    "vocab = list(set([word for doc in all_docs for word in doc if word in glove_vocab]))\n",
    "vocab_ignored = set([word for doc in all_docs for word in doc if word not in glove_vocab])\n",
    "vocab.insert(0, \"<PAD>\")\n",
    "vocab.insert(1, \"<UNK>\")\n",
    "print(vocab)\n",
    "print(vocab_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[150, 139, 182, 244, 83],\n",
       " [282, 266, 66, 109, 151, 159],\n",
       " [132, 50, 5, 103, 242, 164, 88, 155],\n",
       " [124, 45, 264, 86],\n",
       " [211, 50, 155],\n",
       " [282, 199, 45, 200],\n",
       " [34, 77, 9],\n",
       " [228, 241, 151, 207],\n",
       " [5, 240, 50, 161, 177],\n",
       " [282, 251, 182, 224, 255],\n",
       " [10, 27, 21, 183, 88, 254],\n",
       " [151, 310, 311, 126, 97],\n",
       " [197, 268, 120, 27, 247, 54],\n",
       " [88, 46, 301, 92],\n",
       " [282, 312, 250],\n",
       " [34, 11, 138, 244],\n",
       " [31, 110, 56, 115, 235, 57, 57],\n",
       " [126, 80, 236, 93],\n",
       " [5, 146, 167, 49],\n",
       " [282, 131, 135, 90],\n",
       " [264, 190, 45, 160, 21, 272],\n",
       " [10, 50, 88, 169, 199],\n",
       " [261, 187],\n",
       " [132, 4, 271, 130],\n",
       " [215, 50, 155],\n",
       " [5, 12, 194, 141, 83],\n",
       " [282, 266, 299],\n",
       " [282, 266, 264, 89, 182, 225, 45, 62, 264, 177],\n",
       " [45, 27, 243, 241, 45, 23],\n",
       " [148, 28, 136, 242],\n",
       " [247, 50, 264, 100],\n",
       " [197, 81, 45, 213, 294],\n",
       " [198, 45, 251, 182, 295, 244, 99, 127],\n",
       " [282, 121, 201],\n",
       " [10, 50, 32],\n",
       " [45, 245],\n",
       " [10, 231, 56, 59],\n",
       " [247, 50, 179],\n",
       " [10, 85, 181, 182, 184, 278],\n",
       " [233, 178, 50, 264, 105],\n",
       " [13, 202, 132],\n",
       " [282, 266, 89],\n",
       " [282, 119, 88, 137],\n",
       " [228],\n",
       " [142, 147, 4, 283],\n",
       " [45, 67, 160, 100],\n",
       " [88, 52, 50, 256, 108, 5, 68, 157, 244, 76],\n",
       " [142, 41, 50, 69, 244, 156],\n",
       " [198, 45, 110, 51],\n",
       " [45, 312, 56, 43, 6],\n",
       " [282, 257, 45],\n",
       " [282, 193, 282, 131, 285, 60, 125],\n",
       " [282, 312, 70, 273, 88, 116],\n",
       " [45, 160, 291],\n",
       " [282, 287, 203],\n",
       " [142, 50, 264, 271],\n",
       " [148, 19],\n",
       " [247, 50, 5, 223, 279],\n",
       " [282, 266, 114, 182, 5, 238],\n",
       " [45, 160, 281, 154, 216, 71],\n",
       " [34, 11, 138, 244],\n",
       " [168, 50, 151, 227, 279],\n",
       " [282, 110, 45, 56, 59],\n",
       " [282, 124, 93],\n",
       " [88, 145, 167, 305, 56, 302, 212],\n",
       " [282, 296, 93],\n",
       " [282, 251, 185, 211],\n",
       " [73, 160, 261],\n",
       " [14, 47, 50, 264, 274],\n",
       " [79, 99, 5, 122, 132, 312, 56, 59, 109, 26],\n",
       " [10, 189, 289],\n",
       " [247, 27, 8, 39, 187],\n",
       " [5, 106, 50, 78],\n",
       " [282, 4, 48, 99, 14, 99, 67, 30],\n",
       " [271],\n",
       " [282, 110, 132, 55, 94, 47],\n",
       " [282, 199, 137],\n",
       " [165, 160, 264, 15, 216, 123],\n",
       " [264, 174, 294, 45, 95, 21, 208, 91, 84],\n",
       " [247, 236, 289],\n",
       " [282, 266, 264, 104, 273, 151, 172, 182, 142, 82],\n",
       " [282, 266, 138, 5, 289, 146],\n",
       " [79],\n",
       " [246, 56, 115, 35],\n",
       " [282, 251, 182, 72, 7, 99, 127],\n",
       " [282, 266, 248, 205],\n",
       " [247, 95, 21, 198, 204],\n",
       " [130],\n",
       " [148, 72, 211, 74],\n",
       " [10, 50, 264, 100],\n",
       " [124, 45, 88, 63],\n",
       " [282, 266, 186, 99, 56, 64],\n",
       " [282, 266, 214],\n",
       " [282, 270, 88, 191],\n",
       " [45, 249, 5, 102],\n",
       " [57, 57, 57, 132, 4, 264, 271],\n",
       " [198, 45, 251, 182, 96, 244, 56, 275],\n",
       " [168, 50, 107, 164, 5, 16],\n",
       " [10, 50, 58],\n",
       " [45, 160, 21, 111, 99, 142, 292],\n",
       " [282, 199, 88, 144],\n",
       " [142, 303, 4, 304, 56, 41],\n",
       " [261, 41],\n",
       " [142, 309, 50, 258],\n",
       " [45, 293, 21, 128, 132],\n",
       " [282, 266, 264, 58, 99, 45],\n",
       " [3, 241, 5, 17, 187],\n",
       " [282, 266, 66, 109, 45, 181],\n",
       " [282, 251, 182, 25],\n",
       " [294, 24, 61],\n",
       " [5, 152, 284, 40, 312, 5, 29],\n",
       " [142, 50, 174],\n",
       " [45, 27, 21, 198, 151, 252],\n",
       " [282, 131, 72, 56, 206, 300],\n",
       " [198, 45, 72, 56, 29],\n",
       " [5, 297, 160, 258, 276],\n",
       " [160, 45, 43, 99, 289, 142, 230],\n",
       " [246, 160, 5, 65, 109, 5, 146],\n",
       " [282, 266, 195, 256],\n",
       " [209, 50, 5, 238],\n",
       " [10, 50, 5, 306, 140, 282, 72, 259, 280],\n",
       " [171, 160, 219],\n",
       " [247, 50, 307],\n",
       " [161, 174, 294, 45, 101, 21, 162],\n",
       " [45, 160, 56, 217],\n",
       " [282, 199, 290, 211],\n",
       " [168, 50, 43, 99, 56, 220],\n",
       " [247, 305, 182, 267, 56, 87, 188],\n",
       " [282, 266, 153, 211],\n",
       " [246, 50, 192, 91, 45],\n",
       " [282, 199, 45],\n",
       " [258, 187]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_ids = token2id(docs_train_tokens, vocab, unk_id=1)\n",
    "docs_train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[282, 251, 182, 25],\n",
       " [247, 27, 21, 183],\n",
       " [247, 312, 56, 248, 218, 38],\n",
       " [10, 312, 244, 56, 218, 286],\n",
       " [57, 57, 57, 132, 4, 264, 271],\n",
       " [247, 50, 56, 261, 308],\n",
       " [282, 266, 298],\n",
       " [13, 305, 304, 56, 20, 127, 288],\n",
       " [209, 50, 5, 211],\n",
       " [34, 229, 142, 41, 57, 57, 57],\n",
       " [209, 50, 5, 29],\n",
       " [173, 50, 22],\n",
       " [142, 147, 50, 118, 91, 244],\n",
       " [160, 45, 265],\n",
       " [262, 84, 224, 255, 289],\n",
       " [142, 44, 68, 50, 21, 256],\n",
       " [173, 50, 53],\n",
       " [175, 99, 234, 56, 106],\n",
       " [34, 112, 244, 158],\n",
       " [133, 170, 99, 127],\n",
       " [282, 199, 149, 226],\n",
       " [45, 2, 88, 242],\n",
       " [282, 269, 180],\n",
       " [10, 50, 56, 37],\n",
       " [253, 160, 45, 113, 174],\n",
       " [282, 266, 298],\n",
       " [96, 244, 5, 29],\n",
       " [88, 239, 50, 5, 199, 109, 88, 155],\n",
       " [36, 151, 146],\n",
       " [196, 242, 50, 263],\n",
       " [282, 124, 45, 264, 86],\n",
       " [166, 5, 29],\n",
       " [88, 155, 50, 264, 129],\n",
       " [10, 121, 201],\n",
       " [131, 45, 237, 88, 196],\n",
       " [247, 95, 117, 221, 243],\n",
       " [42, 91, 244],\n",
       " [282, 266, 299],\n",
       " [225, 45, 138, 5, 220],\n",
       " [282, 110, 182, 232],\n",
       " [282, 131, 188],\n",
       " [282, 110, 151, 176],\n",
       " [282, 124, 14],\n",
       " [246, 50, 151, 227, 289, 146],\n",
       " [261, 187],\n",
       " [282, 199, 45, 182, 5, 260, 216, 75],\n",
       " [246, 45, 27, 4, 18],\n",
       " [57, 57, 57, 130],\n",
       " [282, 198, 21, 251, 182, 41],\n",
       " [224, 143],\n",
       " [33, 13, 270, 83],\n",
       " [210, 50, 163, 282, 72],\n",
       " [45, 160, 222, 142, 19],\n",
       " [261, 41],\n",
       " [45, 277, 142, 218, 134],\n",
       " [282, 27, 21, 72, 98]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test_ids = token2id(docs_test_tokens, vocab, unk_id=1)\n",
    "docs_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.38919181,  0.66708405,  0.72470655, ..., -0.79198276,\n",
       "         0.92856789,  0.8332264 ],\n",
       "       [ 0.34118   ,  0.13465   , -0.056107  , ..., -0.71771   ,\n",
       "         0.40332   , -0.038861  ],\n",
       "       ..., \n",
       "       [-0.49179   , -0.12295   , -0.50197   , ...,  0.36601   ,\n",
       "         0.43279   , -0.26038   ],\n",
       "       [ 0.54822   ,  0.038847  ,  0.10127   , ...,  0.26588   ,\n",
       "        -0.40267   , -0.17111   ],\n",
       "       [-0.4097    , -0.37167   ,  0.38852   , ..., -0.25414   ,\n",
       "         0.040372  ,  0.38652   ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = build_embedding(glove_file, glove_dim, vocab)\n",
    "embeddings\n",
    "#log.info('got embedding matrix for training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO (preprocess): save vocab, embeddings in metadata file, docs_ids in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  150   139   182  ...      0     0     0\n",
      "  282   266    66  ...      0     0     0\n",
      "  132    50     5  ...    155     0     0\n",
      "       ...          â‹±          ...       \n",
      "  246    50   192  ...      0     0     0\n",
      "  282   199    45  ...      0     0     0\n",
      "  258   187     0  ...      0     0     0\n",
      "[torch.LongTensor of size 132x10]\n",
      "\n",
      "\n",
      "    5\n",
      "    6\n",
      "    8\n",
      "    4\n",
      "    3\n",
      "    4\n",
      "    3\n",
      "    4\n",
      "    5\n",
      "    5\n",
      "    6\n",
      "    5\n",
      "    6\n",
      "    4\n",
      "    3\n",
      "    4\n",
      "    7\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    6\n",
      "    5\n",
      "    2\n",
      "    4\n",
      "    3\n",
      "    5\n",
      "    3\n",
      "   10\n",
      "    6\n",
      "    4\n",
      "    4\n",
      "    5\n",
      "    8\n",
      "    3\n",
      "    3\n",
      "    2\n",
      "    4\n",
      "    3\n",
      "    6\n",
      "    5\n",
      "    3\n",
      "    3\n",
      "    4\n",
      "    1\n",
      "    4\n",
      "    4\n",
      "   10\n",
      "    6\n",
      "    4\n",
      "    5\n",
      "    3\n",
      "    7\n",
      "    6\n",
      "    3\n",
      "    3\n",
      "    4\n",
      "    2\n",
      "    5\n",
      "    6\n",
      "    6\n",
      "    4\n",
      "    5\n",
      "    5\n",
      "    3\n",
      "    7\n",
      "    3\n",
      "    4\n",
      "    3\n",
      "    5\n",
      "   10\n",
      "    3\n",
      "    5\n",
      "    4\n",
      "    8\n",
      "    1\n",
      "    6\n",
      "    3\n",
      "    6\n",
      "    9\n",
      "    3\n",
      "   10\n",
      "    6\n",
      "    1\n",
      "    4\n",
      "    7\n",
      "    4\n",
      "    5\n",
      "    1\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    6\n",
      "    3\n",
      "    4\n",
      "    4\n",
      "    7\n",
      "    8\n",
      "    6\n",
      "    3\n",
      "    7\n",
      "    4\n",
      "    6\n",
      "    2\n",
      "    4\n",
      "    5\n",
      "    6\n",
      "    5\n",
      "    6\n",
      "    4\n",
      "    3\n",
      "    7\n",
      "    3\n",
      "    6\n",
      "    6\n",
      "    5\n",
      "    5\n",
      "    7\n",
      "    7\n",
      "    4\n",
      "    4\n",
      "    9\n",
      "    3\n",
      "    3\n",
      "    7\n",
      "    4\n",
      "    4\n",
      "    6\n",
      "    7\n",
      "    4\n",
      "    5\n",
      "    3\n",
      "    2\n",
      "[torch.LongTensor of size 132x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.LongTensor (len(docs_train_ids), max([len(doc) for doc in docs_train_ids])).fill_(0)\n",
    "X_train_mask = torch.LongTensor (len(docs_train_ids)).fill_(0)\n",
    "for index, doc in enumerate(docs_train_ids):\n",
    "    X_train[index, :len(doc)] = torch.LongTensor(doc)\n",
    "    X_train_mask[index] = len(doc)\n",
    "    \n",
    "X_train_mask = X_train_mask.unsqueeze(1)\n",
    "\n",
    "print(X_train)\n",
    "print(X_train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  282   251   182    25     0     0     0     0\n",
      "  247    27    21   183     0     0     0     0\n",
      "  247   312    56   248   218    38     0     0\n",
      "   10   312   244    56   218   286     0     0\n",
      "   57    57    57   132     4   264   271     0\n",
      "  247    50    56   261   308     0     0     0\n",
      "  282   266   298     0     0     0     0     0\n",
      "   13   305   304    56    20   127   288     0\n",
      "  209    50     5   211     0     0     0     0\n",
      "   34   229   142    41    57    57    57     0\n",
      "  209    50     5    29     0     0     0     0\n",
      "  173    50    22     0     0     0     0     0\n",
      "  142   147    50   118    91   244     0     0\n",
      "  160    45   265     0     0     0     0     0\n",
      "  262    84   224   255   289     0     0     0\n",
      "  142    44    68    50    21   256     0     0\n",
      "  173    50    53     0     0     0     0     0\n",
      "  175    99   234    56   106     0     0     0\n",
      "   34   112   244   158     0     0     0     0\n",
      "  133   170    99   127     0     0     0     0\n",
      "  282   199   149   226     0     0     0     0\n",
      "   45     2    88   242     0     0     0     0\n",
      "  282   269   180     0     0     0     0     0\n",
      "   10    50    56    37     0     0     0     0\n",
      "  253   160    45   113   174     0     0     0\n",
      "  282   266   298     0     0     0     0     0\n",
      "   96   244     5    29     0     0     0     0\n",
      "   88   239    50     5   199   109    88   155\n",
      "   36   151   146     0     0     0     0     0\n",
      "  196   242    50   263     0     0     0     0\n",
      "  282   124    45   264    86     0     0     0\n",
      "  166     5    29     0     0     0     0     0\n",
      "   88   155    50   264   129     0     0     0\n",
      "   10   121   201     0     0     0     0     0\n",
      "  131    45   237    88   196     0     0     0\n",
      "  247    95   117   221   243     0     0     0\n",
      "   42    91   244     0     0     0     0     0\n",
      "  282   266   299     0     0     0     0     0\n",
      "  225    45   138     5   220     0     0     0\n",
      "  282   110   182   232     0     0     0     0\n",
      "  282   131   188     0     0     0     0     0\n",
      "  282   110   151   176     0     0     0     0\n",
      "  282   124    14     0     0     0     0     0\n",
      "  246    50   151   227   289   146     0     0\n",
      "  261   187     0     0     0     0     0     0\n",
      "  282   199    45   182     5   260   216    75\n",
      "  246    45    27     4    18     0     0     0\n",
      "   57    57    57   130     0     0     0     0\n",
      "  282   198    21   251   182    41     0     0\n",
      "  224   143     0     0     0     0     0     0\n",
      "   33    13   270    83     0     0     0     0\n",
      "  210    50   163   282    72     0     0     0\n",
      "   45   160   222   142    19     0     0     0\n",
      "  261    41     0     0     0     0     0     0\n",
      "   45   277   142   218   134     0     0     0\n",
      "  282    27    21    72    98     0     0     0\n",
      "[torch.LongTensor of size 56x8]\n",
      "\n",
      "\n",
      "    4\n",
      "    4\n",
      "    6\n",
      "    6\n",
      "    7\n",
      "    5\n",
      "    3\n",
      "    7\n",
      "    4\n",
      "    7\n",
      "    4\n",
      "    3\n",
      "    6\n",
      "    3\n",
      "    5\n",
      "    6\n",
      "    3\n",
      "    5\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    4\n",
      "    3\n",
      "    4\n",
      "    5\n",
      "    3\n",
      "    4\n",
      "    8\n",
      "    3\n",
      "    4\n",
      "    5\n",
      "    3\n",
      "    5\n",
      "    3\n",
      "    5\n",
      "    5\n",
      "    3\n",
      "    3\n",
      "    5\n",
      "    4\n",
      "    3\n",
      "    4\n",
      "    3\n",
      "    6\n",
      "    2\n",
      "    8\n",
      "    5\n",
      "    4\n",
      "    6\n",
      "    2\n",
      "    4\n",
      "    5\n",
      "    5\n",
      "    2\n",
      "    5\n",
      "    5\n",
      "[torch.LongTensor of size 56x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.LongTensor (len(docs_test_ids), max([len(doc) for doc in docs_test_ids])).fill_(0)\n",
    "X_test_mask = torch.LongTensor (len(docs_test_ids)).fill_(0)\n",
    "for index, doc in enumerate(docs_test_ids):\n",
    "    X_test[index, :len(doc)] = torch.LongTensor (doc)\n",
    "    X_test_mask[index] = len(doc)\n",
    "    \n",
    "X_test_mask = X_test_mask.unsqueeze(1)\n",
    "\n",
    "print(X_test)\n",
    "print(X_test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    X_train = X_train.cuda()\n",
    "    X_train_mask = X_train_mask.cuda()\n",
    "    Y_train = Y_train.cuda()\n",
    "\n",
    "    X_test = X_test.cuda()\n",
    "    X_test_mask = X_test_mask.cuda()\n",
    "    Y_test = Y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.LongTensor'>\n",
      "<class 'torch.LongTensor'>\n",
      "torch.Size([132, 10])\n",
      "torch.Size([132, 1])\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_train_mask))\n",
    "print(X_train.size())\n",
    "print(X_train_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x209c1181898>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = torch.cat((X_train, X_train_mask), 1)\n",
    "test2 = torch.cat((X_test, X_test_mask), 1)\n",
    "#dataset = torch.utils.data.TensorDataset(torch.cat((X_train, X_train_mask), 1), torch.cat((X_test, X_test_mask), 1))\n",
    "dataset = data_utils.TensorDataset(test1, Y_train)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "#TODO: if load model, synchronize random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embeddings, average, \n",
    "class Model1_LR(nn.Module):\n",
    "    def __init__(self, vocab, embeddings, num_classes):\n",
    "        super(Model1_LR, self).__init__()    \n",
    "    \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding_dim = len(embeddings[0])\n",
    "        self.embedding = nn.Embedding(len(vocab),         #vocab size\n",
    "                                      self.embedding_dim, #embedding_dim\n",
    "                                      padding_idx=0)\n",
    "        self.embedding.weight.data = torch.Tensor(embeddings)\n",
    "        #do not backprop into embeddings\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        #linear layer\n",
    "        self.linear = nn.Linear(self.embedding_dim, num_classes)\n",
    "        #nn.init.xavier_normal(self.linear.weight)\n",
    "        #self.linear.bias.data.zero_()\n",
    "     \n",
    "    def forward(self, X, X_mask):\n",
    "        #X: [m, Tx] m = batch size, Tx = word count\n",
    "        #print(X.size(), type(X))\n",
    "        m = X.size()[0]\n",
    "        Tx = X.size()[1]\n",
    "        \n",
    "        X = self.embedding(X)\n",
    "        #X: [m, Tx, embedding_dim] m = batch size, Tx = word count\n",
    "        #print(X.size(), type(X.data))\n",
    "        assert X.size() == torch.Size([m, Tx, self.embedding_dim])\n",
    "                \n",
    "        #average words in doc. use mask so we average only words not padding\n",
    "        X = torch.sum(X, 1)\n",
    "        X = Variable(torch.div(X.data, X_mask))\n",
    "        #X: [m, emb_dim]\n",
    "        #print(X.size(), type(X.data))\n",
    "        assert X.size() == torch.Size([m, self.embedding_dim])\n",
    "        \n",
    "        X = self.linear(X)\n",
    "        #X: [m, 1]\n",
    "        #print(X.size(), type(X))\n",
    "        assert X.size() == torch.Size([m, self.num_classes])\n",
    "        \n",
    "        return F.softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1_LR(vocab, embeddings, num_classes)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-2)\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2_LSTM(nn.Module):\n",
    "    def __init__(self, vocab, embeddings, num_classes):\n",
    "        super(Model2_LSTM, self).__init__()    \n",
    "    \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding_dim = len(embeddings[0])\n",
    "        self.embedding = nn.Embedding(len(vocab),         #vocab size\n",
    "                                      self.embedding_dim, #embedding_dim\n",
    "                                      padding_idx=0)\n",
    "        self.embedding.weight.data = torch.Tensor(embeddings)\n",
    "        #do not backprop into embeddings\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        #LSTM1, hidden_size = 128\n",
    "        #TODO: try bidirectional=True\n",
    "        self.LSTM1_hidden_size = 128\n",
    "        self.LSTM1 = nn.LSTM(self.embedding_dim, self.LSTM1_hidden_size)\n",
    "        \n",
    "        #dropout\n",
    "        self.dropout = nn.Dropout()\n",
    "     \n",
    "        #LSTM, hidden_size = 128\n",
    "        #TODO: try bidirectional=True\n",
    "        self.LSTM2_hidden_size = 128\n",
    "        self.LSTM2 = nn.LSTM(self.LSTM1_hidden_size, self.LSTM2_hidden_size)\n",
    "        \n",
    "        #linear layer\n",
    "        self.linear = nn.Linear(self.LSTM2_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, X, X_mask):\n",
    "        #X: [m, Tx] m = batch size, Tx = word count\n",
    "        #print(X.size(), type(X))\n",
    "        m = X.size()[0]\n",
    "        Tx = X.size()[1]\n",
    "\n",
    "        #embedding layer\n",
    "        X = self.embedding(X)\n",
    "        #X: [m, Tx, embedding_dim] \n",
    "        #print(X.size(), type(X.data))\n",
    "        assert X.size() == torch.Size([m, Tx, self.embedding_dim])\n",
    "           \n",
    "        #LSTM1\n",
    "        # Transpose batch and sequence dims\n",
    "        X = X.transpose(0, 1)\n",
    "        X, _ = self.LSTM1(X)\n",
    "        # Transpose back\n",
    "        X = X.transpose(0, 1)\n",
    "        #X: [m, Tx, LSTM1_hidden_size] \n",
    "        #print(X.size(), type(X.data))\n",
    "        assert X.size() == torch.Size([m, Tx, self.LSTM1_hidden_size])\n",
    "        \n",
    "        #dropout\n",
    "        X = self.dropout(X)\n",
    "\n",
    "        #LSTM2, reduce dimension\n",
    "        # Transpose batch and sequence dims\n",
    "        X = X.transpose(0, 1)\n",
    "        _, X = self.LSTM2(X)\n",
    "        X = X[0]\n",
    "        # Transpose back\n",
    "        X = X.transpose(0, 1)\n",
    "        X = torch.squeeze(X)\n",
    "        #X: [m, LSTM2_hidden_size] \n",
    "        #print(X.size(), type(X.data))\n",
    "        assert X.size() == torch.Size([m, self.LSTM2_hidden_size])\n",
    "        \n",
    "        #dropout\n",
    "        X = self.dropout(X)\n",
    "\n",
    "        #linear\n",
    "        X = self.linear(X)\n",
    "        #X: [m, 1]\n",
    "        #print(X.size(), type(X))\n",
    "        assert X.size() == torch.Size([m, self.num_classes])\n",
    "        \n",
    "        return F.softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model2_LSTM(vocab, embeddings, num_classes)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1_LR (\n",
       "  (embedding): Embedding(313, 50, padding_idx=0)\n",
       "  (linear): Linear (50 -> 5)\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 5])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.6082\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#workaround: X_train_mask to float so div works. Must be done before .cuda() call\n",
    "X_train_mask = torch.FloatTensor(X_train_mask.numpy().astype(float))\n",
    "Y_predict = model(X_train, X_train_mask)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(Y_predict, Y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 003300 loss 1.4388 train acc 0.5606 test acc 0.5357\n",
      "epoch 003400 loss 1.4361 train acc 0.5606 test acc 0.5357\n",
      "epoch 003500 loss 1.4335 train acc 0.5682 test acc 0.5357\n",
      "epoch 003600 loss 1.4309 train acc 0.5682 test acc 0.5357\n",
      "epoch 003700 loss 1.4284 train acc 0.5682 test acc 0.5357\n",
      "epoch 003800 loss 1.4260 train acc 0.5758 test acc 0.5357\n",
      "epoch 003900 loss 1.4236 train acc 0.5833 test acc 0.5357\n",
      "epoch 004000 loss 1.4213 train acc 0.5833 test acc 0.5357\n",
      "epoch 004100 loss 1.4191 train acc 0.5833 test acc 0.5536\n",
      "epoch 004200 loss 1.4169 train acc 0.5833 test acc 0.5536\n"
     ]
    }
   ],
   "source": [
    "#TODO: use DataLoader, batches\n",
    "#move workaround just before div\n",
    "#workaround: X_train_mask to float so div works. Must be done before .cuda() call\n",
    "X_train_mask = torch.FloatTensor(X_train_mask.numpy().astype(float))\n",
    "X_test_mask = torch.FloatTensor(X_test_mask.numpy().astype(float))\n",
    "for epoch_local in range(1000):\n",
    "    #Forward pass\n",
    "    model.train()\n",
    "\n",
    "    Y_predict = model(X_train, X_train_mask)\n",
    "\n",
    "    #Compute loss\n",
    "    loss = criterion(Y_predict, Y_train)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        #Calculate train and test accuracy\n",
    "        _, Y_predict = torch.max(Y_predict, 1)\n",
    "        correct = (Y_predict == Y_train).sum()\n",
    "        correct = correct.cpu().data.numpy()[0]\n",
    "        accuracy_train = correct/Y_train.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        Y_predict = model(X_test, X_test_mask)\n",
    "        _, Y_predict = torch.max(Y_predict, 1)\n",
    "        correct = (Y_predict == Y_test).sum()\n",
    "        correct = correct.cpu().data.numpy()[0]\n",
    "        accuracy_test = correct/Y_test.size(0)\n",
    "        \n",
    "        print(\"epoch {0:06d} loss {1:.4f} train acc {2:.4f} test acc {3:.4f}\".format(epoch, loss.cpu().data.numpy()[0], accuracy_train, accuracy_test))\n",
    "\n",
    "    #Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 3\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 0\n",
       " 4\n",
       " 0\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 4\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 4\n",
       "[torch.cuda.LongTensor of size 56 (GPU 0)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = model(X_test, X_test_mask)\n",
    "_, Y_predict = torch.max(Y_predict, 1)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  1,  0,  0,  0],\n",
       "       [ 2,  5,  1,  0,  0],\n",
       "       [ 4,  0, 13,  0,  1],\n",
       "       [ 6,  2,  0,  8,  0],\n",
       "       [ 0,  2,  1,  0,  4]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test.data.cpu().numpy(), Y_predict.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I love taking breaks\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>My grandmother is the love of my life\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I miss you so much\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I like your jacket \\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>i miss her\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I love you to the stars and back\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>family is all I have\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0  1\n",
       "20                   I love taking breaks\\t  0\n",
       "27  My grandmother is the love of my life\\t  0\n",
       "30                     I miss you so much\\t  0\n",
       "41                    I like your jacket \\t  0\n",
       "42                             i miss her\\t  0\n",
       "45       I love you to the stars and back\\t  0\n",
       "51                   family is all I have\\t  0"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test[1] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 I love taking breaks\t\n",
      "30 I miss you so much\t\n",
      "42 i miss her\t\n",
      "51 family is all I have\t\n"
     ]
    }
   ],
   "source": [
    "for i in df_test[df_test[1] == 0].index:\n",
    "    if Y_predict[i].data.numpy()[0] == 3:\n",
    "        print(i, df_test.iloc[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
